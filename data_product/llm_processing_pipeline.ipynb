{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff18d4d6",
   "metadata": {},
   "source": [
    "# Identifying Inadmissibility Cases in Canadian Federal Court Decisions (2014–2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d23acd",
   "metadata": {},
   "source": [
    "## Step 1: Library Imports\n",
    "Import all necessary libraries to load the dataset, process the text, and interact with external models.\n",
    "\n",
    "- `pandas`: Used for tabular data manipulation.\n",
    "\n",
    "- `re`: Python's built-in module for regular expressions to detect legal patterns.\n",
    "\n",
    "- `subprocess`: Executes command-line commands, useful for interacting with external tools like LLaMA 3.\n",
    "\n",
    "- `datasets`: Provides access to HuggingFace datasets.\n",
    "\n",
    "- `tqdm`: Displays progress bars for loops, particularly useful when processing a large number of court cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806aee30",
   "metadata": {},
   "source": [
    "To run this notebook from step 8, you will need to:\n",
    "1. Download Ollam from [here](https://ollama.com/)\n",
    "2. Go to your terminal and type: `ollama pull llama3` to download llama3 model in your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60d0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/husain/miniforge3/envs/heron_law/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tqdm as notebook_tqdm\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import datetime\n",
    "import re\n",
    "import subprocess\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abe1c8",
   "metadata": {},
   "source": [
    "## Step 2: Loading and Filtering the Dataset (2014–2024)\n",
    "Load the Federal Court dataset and retain only decisions published between 2014 and 2024.\n",
    "\n",
    "- The dataset is retrieved using the datasets library from HuggingFace.\n",
    "\n",
    "- It contains metadata and full decision texts from the Canadian Federal Court.\n",
    "\n",
    "- The filtering ensures temporal relevance for the study, focusing on contemporary jurisprudence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ffa1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 63568/63568 [00:01<00:00, 34419.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"refugee-law-lab/canadian-legal-data\", \"FC\", split=\"train\")\n",
    "FC = dataset.to_pandas()\n",
    "FC_2014_2024 = FC.query(\"year >= 2014\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208ee2e",
   "metadata": {},
   "source": [
    "## Step 3: Removing Translated Versions (French Duplicates)\n",
    "Eliminate French translations when English versions of the same case are available.\n",
    "\n",
    "- Decisions can be published in both English and French.\n",
    "\n",
    "- To avoid duplication and inconsistencies, the script standardizes the citation by replacing court acronyms (e.g., \"FC\", \"CF\") with a generic placeholder.\n",
    "\n",
    "- French entries are removed only if a corresponding English version exists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476b971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_translated_cases(df, citation_col='citation', lang_col='language', lang_primary='en', lang_secondary='fr'):\n",
    "    \"\"\"\n",
    "    Removes rows in the secondary language (e.g., French) that are translations of cases already \n",
    "    present in the primary language (e.g., English), based on normalized court citations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame containing legal case data.\n",
    "    citation_col : str, optional\n",
    "        The name of the column containing case citations. Default is 'citation'.\n",
    "    lang_col : str, optional\n",
    "        The name of the column containing language information. Default is 'language'.\n",
    "    lang_primary : str, optional\n",
    "        The language code to be considered as the primary version (e.g., 'en'). Default is 'en'.\n",
    "    lang_secondary : str, optional\n",
    "        The language code to be considered as the translated version to remove (e.g., 'fr'). Default is 'fr'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A filtered DataFrame with translated cases removed when the same case exists in the primary language.\n",
    "    \"\"\"\n",
    "    court_acronyms = ['FC', 'CF'] \n",
    "    pattern = r'\\b(' + '|'.join(court_acronyms) + r')\\b'\n",
    "\n",
    "    def normalize(citation):\n",
    "        return re.sub(pattern, 'COURT', citation)\n",
    "\n",
    "    df = df.copy()\n",
    "    df['normalized_citation'] = df[citation_col].apply(normalize)\n",
    "\n",
    "    primary_citations = set(df[df[lang_col] == lang_primary]['normalized_citation'])\n",
    "\n",
    "    filtered_df = df[~((df[lang_col] == lang_secondary) & (df['normalized_citation'].isin(primary_citations)))]\n",
    "\n",
    "    return filtered_df.drop(columns=['normalized_citation'])\n",
    "\n",
    "FC_remove_translation = remove_translated_cases(FC_2014_2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248b3cd",
   "metadata": {},
   "source": [
    "## Step 4: Isolating Immigration-Related Decisions\n",
    "Filter for cases specifically related to immigration matters.\n",
    "\n",
    "- The approach checks for the presence of immigration-related terms within the first 10 lines of each decision.\n",
    "\n",
    "- Keywords include “Citizenship and Immigration”, “Citoyenneté et Immigration”, and “MCI” (Minister of Citizenship and Immigration).\n",
    "\n",
    "- This step narrows the dataset to immigration law cases and excludes unrelated legal issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8a3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def immigration_cases(text):\n",
    "    \"\"\"\n",
    "    Checks whether the given text contains references to immigration-related ministries \n",
    "    within the first 10 lines.\n",
    "\n",
    "    This function is typically used to filter legal case documents that mention \n",
    "    either \"Citizenship and Immigration\" or \"Citoyenneté et Immigration\" early in the text.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    text : str or None\n",
    "        The textual content of a legal case, potentially containing multiple lines.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool\n",
    "        True if either phrase appears in the first 10 lines of the text; False otherwise.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    lines = text.splitlines()[:10]\n",
    "    joined_lines = ' '.join(lines)\n",
    "    return (\n",
    "        # \"Public Safety\" in joined_lines or\n",
    "        # \"Immigration, Refugees and Citizenship\" in joined_lines or\n",
    "        \"Citizenship and Immigration\" in joined_lines or\n",
    "        \"Citoyenneté et Immigration\" in joined_lines or\n",
    "        \"MCI\" in joined_lines\n",
    "    )\n",
    "\n",
    "FC_immigration = FC_remove_translation[FC_remove_translation['unofficial_text'].apply(immigration_cases)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab7b2e",
   "metadata": {},
   "source": [
    "## Step 5: Removing Refugee Claims\n",
    "Exclude cases dealing with refugee protection to focus exclusively on inadmissibility under the Immigration and Refugee Protection Act (IRPA).\n",
    "\n",
    "- A comprehensive regular expression is used to detect references to refugee claims, protected persons, and related terminology.\n",
    "\n",
    "- These cases are removed since the legal framework and reasoning differ substantially from inadmissibility cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ee0877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f9/98mwc4pn4l51n7xqzs0w7ryh0000gn/T/ipykernel_52387/1655259967.py:19: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = ~df[text_column].str.contains(RE_exclude_refugee, na=False)\n"
     ]
    }
   ],
   "source": [
    "RE_exclude_refugee = re.compile(\n",
    "    r'\\b(Refugee Protection Division|convention refugees?|persons? in need of protection|refugee claimants?|protected persons?|réfugiés?)\\b',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def filter_refugee_cases(df, text_column=\"unofficial_text\"):\n",
    "    \"\"\"\n",
    "    Removes rows containing refugee exclusion terms from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    text_column : str\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame: Filtered DataFrame without refugee-related documents\n",
    "    \"\"\"\n",
    "    mask = ~df[text_column].str.contains(RE_exclude_refugee, na=False)\n",
    "    return df[mask].copy()\n",
    "\n",
    "FC_non_refugee = filter_refugee_cases(FC_immigration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148449aa",
   "metadata": {},
   "source": [
    "## Step 6: Filtering by Inadmissibility Mentions\n",
    "Retain only those cases that explicitly mention “inadmissibility” or “inadmissible.”\n",
    "\n",
    "- This is a keyword-based filter using simple substring checks.\n",
    "\n",
    "- It helps narrow down the dataset to decisions where inadmissibility is central to the legal reasoning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83dd592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_inadmissibility(df, text_column=\"unofficial_text\"):\n",
    "    \"\"\"\n",
    "    Filters rows in the DataFrame that contain 'inadmissible' or 'inadmissibility'\n",
    "    in the relevant numbered lines extracted from the specified text column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    text_column (str): Name of the column containing case text\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame with only relevant cases\n",
    "    \"\"\"\n",
    "\n",
    "    return df[df[text_column].apply(lambda text: \n",
    "           'inadmissible' in text.lower() or\n",
    "           'inadmissibility' in text.lower())]\n",
    "\n",
    "FC_inadmissible = filter_inadmissibility(FC_non_refugee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7cbe8",
   "metadata": {},
   "source": [
    "## Step 7: Categorizing Inadmissibility Grounds under IRPA\n",
    "This step aims to automatically classify each court decision into one or more categories of inadmissibility, as defined in the Immigration and Refugee Protection Act (IRPA), using both:\n",
    "\n",
    "- Explicit references to IRPA sections (e.g., s.34, s.36(1))\n",
    "\n",
    "- Implicit references through legal keywords and concepts\n",
    "\n",
    "**Components Involved**\n",
    "1. SECTION_PATTERNS Dictionary\n",
    "This dictionary maps each inadmissibility ground to a regular expression (regex) designed to match explicit references to legal provisions in the IRPA.\n",
    "Each key corresponds to a legal category, and each value is a compiled regex that detects citations like “section 34” or “s.36(1)” within the decision text.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- \"security\" → section 34 IRPA\n",
    "\n",
    "- \"serious_criminality\" → section 36(1)\n",
    "\n",
    "- \"misrepresentation\" → section 40\n",
    "\n",
    "2. RE_patterns Dictionary\n",
    "This dictionary maps each ground to a regex that captures semantic/legal terms that often imply the corresponding section, even without explicit citation.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- \"security\" → matches terms like “espionage”, “terrorism”, “subversion”\n",
    "\n",
    "- \"criminality\" → matches “convictions”, “summary offences”, “indictable”\n",
    "\n",
    "- \"health_grounds\" → detects “danger to public health” or “excessive demand on health services”\n",
    "\n",
    "**Function: categorize_document(text)**\n",
    "\n",
    "To classify a court decision into one or more grounds of inadmissibility, based on either:\n",
    "\n",
    "- Section citations (preferred)\n",
    "\n",
    "- Legal semantics (fallback)\n",
    "\n",
    "If neither is found, the case is classified as 'other'\n",
    "\n",
    "**Execution Flow:**\n",
    "Step 1: Extract Numbered Legal Paragraphs\n",
    "- The decision is split into lines.\n",
    "\n",
    "- Extraction starts from the first paragraph labeled [1].\n",
    "\n",
    "- Only lines with paragraph numbers like [12] or numbered sentences (e.g., 12.) are retained.\n",
    "\n",
    "- This section is usually the legal reasoning portion of the decision.\n",
    "\n",
    "Step 2: Match Explicit Section Patterns\n",
    "- Each regex in SECTION_PATTERNS is applied to the extracted portion.\n",
    "\n",
    "- If a section match is found (e.g., “section 36(1)”), the corresponding ground (e.g., serious_criminality) is returned immediately as a single-element list.\n",
    "\n",
    "Step 3: Fallback to Keyword Patterns\n",
    "- If no section is found, each regex in RE_patterns is applied.\n",
    "\n",
    "- Multiple matches can occur; the function returns a list of all matching grounds.\n",
    "\n",
    "Step 4: Default Classification\n",
    "- If neither section citations nor relevant keywords are found, the case is labeled as ['other']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce86c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f9/98mwc4pn4l51n7xqzs0w7ryh0000gn/T/ipykernel_52387/1786685229.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  FC_inadmissible['inadmissibility_ground'] = FC_inadmissible['unofficial_text'].apply(categorize_document)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citation</th>\n",
       "      <th>citation2</th>\n",
       "      <th>dataset</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "      <th>document_date</th>\n",
       "      <th>source_url</th>\n",
       "      <th>scraped_timestamp</th>\n",
       "      <th>unofficial_text</th>\n",
       "      <th>other</th>\n",
       "      <th>inadmissibility_ground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18532</th>\n",
       "      <td>2014 FC 105</td>\n",
       "      <td></td>\n",
       "      <td>FC</td>\n",
       "      <td>2014</td>\n",
       "      <td>Muthui v. Canada (Citizenship and Immigration)</td>\n",
       "      <td>en</td>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>https://decisions.fct-cf.gc.ca/fc-cf/decisions...</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>Muthui v. Canada (Citizenship and Immigration)...</td>\n",
       "      <td></td>\n",
       "      <td>[inadmissible_family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18595</th>\n",
       "      <td>2014 FC 112</td>\n",
       "      <td></td>\n",
       "      <td>FC</td>\n",
       "      <td>2014</td>\n",
       "      <td>Adewole v. Canada (Citizenship and Immigration)</td>\n",
       "      <td>en</td>\n",
       "      <td>2014-02-04</td>\n",
       "      <td>https://decisions.fct-cf.gc.ca/fc-cf/decisions...</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>Adewole v. Canada (Citizenship and Immigration...</td>\n",
       "      <td></td>\n",
       "      <td>[other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18609</th>\n",
       "      <td>2014 FC 1137</td>\n",
       "      <td></td>\n",
       "      <td>FC</td>\n",
       "      <td>2014</td>\n",
       "      <td>Sidhu v. Canada (Citizenship and Immigration)</td>\n",
       "      <td>en</td>\n",
       "      <td>2014-11-25</td>\n",
       "      <td>https://decisions.fct-cf.gc.ca/fc-cf/decisions...</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>Sidhu v. Canada (Citizenship and Immigration)\\...</td>\n",
       "      <td></td>\n",
       "      <td>[other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18617</th>\n",
       "      <td>2014 FC 1146</td>\n",
       "      <td></td>\n",
       "      <td>FC</td>\n",
       "      <td>2014</td>\n",
       "      <td>Abebe v. Canada (Citizenship and Immigration)</td>\n",
       "      <td>en</td>\n",
       "      <td>2014-11-28</td>\n",
       "      <td>https://decisions.fct-cf.gc.ca/fc-cf/decisions...</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>Abebe v. Canada (Citizenship and Immigration)\\...</td>\n",
       "      <td></td>\n",
       "      <td>[security]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18618</th>\n",
       "      <td>2014 FC 1147</td>\n",
       "      <td></td>\n",
       "      <td>FC</td>\n",
       "      <td>2014</td>\n",
       "      <td>Bundhel v. Canada (Citizenship and Immigration)</td>\n",
       "      <td>en</td>\n",
       "      <td>2014-11-28</td>\n",
       "      <td>https://decisions.fct-cf.gc.ca/fc-cf/decisions...</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>Bundhel v. Canada (Citizenship and Immigration...</td>\n",
       "      <td></td>\n",
       "      <td>[other]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           citation citation2 dataset  year  \\\n",
       "18532   2014 FC 105                FC  2014   \n",
       "18595   2014 FC 112                FC  2014   \n",
       "18609  2014 FC 1137                FC  2014   \n",
       "18617  2014 FC 1146                FC  2014   \n",
       "18618  2014 FC 1147                FC  2014   \n",
       "\n",
       "                                                  name language document_date  \\\n",
       "18532   Muthui v. Canada (Citizenship and Immigration)       en    2014-01-30   \n",
       "18595  Adewole v. Canada (Citizenship and Immigration)       en    2014-02-04   \n",
       "18609    Sidhu v. Canada (Citizenship and Immigration)       en    2014-11-25   \n",
       "18617    Abebe v. Canada (Citizenship and Immigration)       en    2014-11-28   \n",
       "18618  Bundhel v. Canada (Citizenship and Immigration)       en    2014-11-28   \n",
       "\n",
       "                                              source_url scraped_timestamp  \\\n",
       "18532  https://decisions.fct-cf.gc.ca/fc-cf/decisions...        2022-08-23   \n",
       "18595  https://decisions.fct-cf.gc.ca/fc-cf/decisions...        2022-08-23   \n",
       "18609  https://decisions.fct-cf.gc.ca/fc-cf/decisions...        2022-08-23   \n",
       "18617  https://decisions.fct-cf.gc.ca/fc-cf/decisions...        2022-08-23   \n",
       "18618  https://decisions.fct-cf.gc.ca/fc-cf/decisions...        2022-08-23   \n",
       "\n",
       "                                         unofficial_text other  \\\n",
       "18532  Muthui v. Canada (Citizenship and Immigration)...         \n",
       "18595  Adewole v. Canada (Citizenship and Immigration...         \n",
       "18609  Sidhu v. Canada (Citizenship and Immigration)\\...         \n",
       "18617  Abebe v. Canada (Citizenship and Immigration)\\...         \n",
       "18618  Bundhel v. Canada (Citizenship and Immigration...         \n",
       "\n",
       "      inadmissibility_ground  \n",
       "18532  [inadmissible_family]  \n",
       "18595                [other]  \n",
       "18609                [other]  \n",
       "18617             [security]  \n",
       "18618                [other]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SECTION_PATTERNS = {\n",
    "    'security': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*34\\b|\\b34\\(\\d+\\)', re.IGNORECASE),\n",
    "    'human_rights': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*35\\b|\\b35\\(\\d+\\)', re.IGNORECASE),\n",
    "    'serious_criminality': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*36\\(1\\)', re.IGNORECASE),\n",
    "    'criminality': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*36\\(2\\)', re.IGNORECASE),\n",
    "    'organized_criminality': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*37\\b|\\b37\\(\\d+\\)', re.IGNORECASE),\n",
    "    'health_grounds': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*38\\b|\\b38\\(\\d+\\)', re.IGNORECASE),\n",
    "    'financial_reasons': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*39\\b|\\b39\\(\\d+\\)', re.IGNORECASE),\n",
    "    'misrepresentation': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*40\\b|\\b40\\(\\d+\\)', re.IGNORECASE),\n",
    "    'non_compliance': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*41\\b|\\b41\\(\\d+\\)', re.IGNORECASE),\n",
    "    'inadmissible_family': re.compile(r'\\b(?:s(?:ection)?\\.?\\s*|subsection|paragraphs?)\\s*42\\b|\\b42\\(\\d+\\)', re.IGNORECASE)\n",
    "}\n",
    "\n",
    "RE_patterns = {\n",
    "    'security': re.compile(\n",
    "        r'\\b(espionages?|against canada|canada[’\\'‘s]* interests?|subversions?|democratic governments?|terrorisms?|dangers? to security|violences?|endangerments?|memberships?|complicity|reasonable grounds? to believe)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'human_rights': re.compile(\n",
    "        r'\\b(human rights?|international rights?|violations?|senior officials?|governments?|regimes?|genocides?|war crimes?|crimes? against humanity|participations?|contributions?|reasonable grounds? to believe|terrorisms?)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'serious_criminality': re.compile(\n",
    "        r'\\b(criminal convictions?|foreign convictions?|imprisonments?|10 years|ten years|sentences?|over (6|six) months|serious indictable offences?|commissions?|reasonable grounds? to believe)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'criminality': re.compile(\n",
    "        r'\\b(criminal convictions?|foreign convictions?|indictments?|indictable offences?|summary offences?|commissions?)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'organized_criminality': re.compile(\n",
    "        r'\\b(memberships?|criminal activities?|organized crimes?|acting in concert|people smuggling|traffickings?|money launderings?|proceeds? of crime|reasonable grounds? to believe)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'health_grounds': re.compile(\n",
    "        r'\\b(dangers? to public health|dangers? to public safety|excessive demands? on health services|excessive demands? on social services)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'financial_reasons': re.compile(\n",
    "        r'\\b(unable or unwilling to support (oneself|dependents?)|arrangements? for care and support|social assistances?)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'misrepresentation': re.compile(\n",
    "        r'\\b(misrepresenting|withholding|material facts?|errors? in administration|non-disclosures?|omissions?|false statements?|false information)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'non_compliance': re.compile(\n",
    "        r'\\b(contraventions?|non-compliances?|failures? to comply)\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'inadmissible_family': re.compile(\n",
    "        r'\\b(inadmissible family members?|accompanying family members?)\\b',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "}\n",
    "\n",
    "def categorize_document(text):\n",
    "    \"\"\"\n",
    "    Extracts relevant numbered lines and classifies a legal document \n",
    "    into IRPA inadmissibility grounds.\n",
    "\n",
    "    Returns:\n",
    "    - [single ground] if a section is matched.\n",
    "    - [multiple grounds] if matched by keyword.\n",
    "    - ['other'] if nothing matches.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    text : str\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list of str\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Extract relevant numbered lines\n",
    "    lines = text.splitlines()\n",
    "    extracted = []\n",
    "    start_extracting = False\n",
    "\n",
    "    for line in lines:\n",
    "        line_strip = line.strip()\n",
    "        if not start_extracting:\n",
    "            if \"[1]\" in line_strip:\n",
    "                extracted.append(line)\n",
    "                start_extracting = True\n",
    "        else:\n",
    "            if line_strip.startswith(\"[\") and line_strip[1:line_strip.find(\"]\")].isdigit():\n",
    "                extracted.append(line)\n",
    "            elif line_strip and line_strip[0].isdigit():\n",
    "                extracted.append(line)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    extracted_text = \"\\n\".join(extracted)\n",
    "\n",
    "    # Step 2: Check section patterns\n",
    "    for category, pattern in SECTION_PATTERNS.items():\n",
    "        if re.search(pattern, extracted_text):\n",
    "            return [category]\n",
    "\n",
    "    # Step 3: Fallback to keyword patterns\n",
    "    matched_keywords = [\n",
    "        category for category, pattern in RE_patterns.items()\n",
    "        if re.search(pattern, extracted_text)\n",
    "    ]\n",
    "\n",
    "    return matched_keywords if matched_keywords else ['other']\n",
    "\n",
    "FC_inadmissible['inadmissibility_ground'] = FC_inadmissible['unofficial_text'].apply(categorize_document)\n",
    "FC_inadmissible.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23726ca",
   "metadata": {},
   "source": [
    "## Step 8: Validating Inadmissibility with LLaMA 3 (LLM-Based Review)\n",
    "Use a large language model (LLaMA 3) to validate whether the case is indeed about inadmissibility and generate a concise summary.\n",
    "\n",
    "- A two-step prompt system is employed:\n",
    "\n",
    "    - Summarization: Generate a 2-line summary of the case.\n",
    "\n",
    "    - Binary Classification: Determine whether the decision primarily concerns inadmissibility.\n",
    "\n",
    "- This approach ensures higher precision than regex alone and serves as a second-level validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_inadmissibility(df, text_column=\"unofficial_text\", model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Classify each court case using LLaMA 3 via subprocess by:\n",
    "    1. Extracting numbered sections starting from [1].\n",
    "    2. Summarizing the extracted text.\n",
    "    3. Feeding the summary into a classification prompt.\n",
    "\n",
    "    This version returns the raw classification output from the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing court case texts.\n",
    "    text_column : str, optional\n",
    "        The name of the column containing the court text (default is \"unofficial_text\").\n",
    "    model : str, optional\n",
    "        The name of the language model to use with Ollama (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame with an added column 'inadmissibility' containing the raw model output.\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_numbered_lines(text):\n",
    "        lines = text.splitlines()\n",
    "        extracted = []\n",
    "        start_extracting = False\n",
    "\n",
    "        for line in lines:\n",
    "            line_strip = line.strip()\n",
    "            if not start_extracting:\n",
    "                # Start if line contains \"[1]\" anywhere\n",
    "                if \"[1]\" in line_strip:\n",
    "                    extracted.append(line)\n",
    "                    start_extracting = True\n",
    "            else:\n",
    "                # Continue only if line starts with [number] or number\n",
    "                if line_strip.startswith(\"[\") and line_strip[1:line_strip.find(\"]\")].isdigit():\n",
    "                    extracted.append(line)\n",
    "                elif line_strip and line_strip[0].isdigit():\n",
    "                    extracted.append(line)\n",
    "                else:\n",
    "                    break\n",
    "        return \"\\n\".join(extracted)\n",
    "\n",
    "    def run_ollama(prompt):\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"ollama\", \"run\", model],\n",
    "                input=prompt.encode(),\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE\n",
    "            )\n",
    "            return result.stdout.decode().strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Subprocess error: {e}\")\n",
    "            return \"subprocess_error\"\n",
    "\n",
    "    def generate_summary(text):\n",
    "        prompt = f\"\"\"\n",
    "You are a legal analyst specializing in Canadian immigration law.\n",
    "\n",
    "Summarize the following court case in one sentence, clearly stating what the case is about.\n",
    "\n",
    "Case Text:\n",
    "{text}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        return run_ollama(prompt)\n",
    "\n",
    "    def classify_summary(summary):\n",
    "        prompt = f\"\"\"\n",
    "You are a Canadian immigration law expert.\n",
    "\n",
    "Based on the following summary of a legal case, classify whether the case involves \n",
    "a judicial review of an inadmissibility decision under Canadian immigration law.\n",
    "\n",
    "\n",
    "Respond only with one of the following:\n",
    "Inadmissibility\n",
    "Not Inadmissibility\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Classification:\n",
    "\"\"\"\n",
    "        return run_ollama(prompt)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"inadmissibility\"] = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        full_text = row[text_column]\n",
    "        limited_text = extract_numbered_lines(full_text)\n",
    "        summary = generate_summary(limited_text)\n",
    "        raw_output = classify_summary(summary)\n",
    "        df.at[idx, \"inadmissibility\"] = raw_output\n",
    "        print(f\"Row {idx} classified.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "inadmissibility_df = classify_inadmissibility(FC_inadmissible)\n",
    "inadmissibility_df = inadmissibility_df.query(\"inadmissibility == 'Inadmissibility'\")\n",
    "inadmissibility_df = inadmissibility_df.drop(\"inadmissibility\", axis=1)\n",
    "inadmissibility_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea49f0",
   "metadata": {},
   "source": [
    "## Step 9: Judge Name Extraction\n",
    "Use llama3 from Ollama (LLM) to extract judge names.\n",
    "\n",
    "- Analyzes the first 30 lines of each court case to locate judicial information, which is typically stated early in the decision.\n",
    "\n",
    "- Uses a model-generated prompt to return a sentence identifying the judges, or indicates their absence.\n",
    "\n",
    "- Extracts only the judge names (stripped of titles) from the generated sentence and stores them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b527db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_judge_sentence(text, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Generate a sentence identifying the judges in a given court text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The court text to analyze.\n",
    "    model : str, optional\n",
    "        The name of the language model to use (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A sentence either listing the judges or stating that none are mentioned.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a legal assistant. Your task is to identify the names of the judge(s) who presided over the case from the following court text.\n",
    "\n",
    "Instructions:\n",
    "- Return a single sentence that starts with \"The judges in this case are ...\" followed by the judge names.\n",
    "- If no judge is mentioned, return \"No judges are mentioned in the case.\"\n",
    "- Do not assume any judges if it is not mentioned.\n",
    "- Keep your answer in 1 sentence.\n",
    "\n",
    "Court Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    return result.stdout.decode().strip()\n",
    "\n",
    "\n",
    "def extract_names_from_judge_sentence(sentence, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Extract only the judge names from a sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        A sentence that mentions the judges (e.g., output of `generate_judge_sentence`).\n",
    "    model : str, optional\n",
    "        The name of the language model to use (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        A list of judge names with titles removed. Returns an empty list if no names are found.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a legal parser. Extract only the judge names from the sentence below.\n",
    "\n",
    "Instructions:\n",
    "- Return the names in a valid Python list of strings.\n",
    "- Do not include any titles like \"Judge\", \"Justice\", or \"Chief Justice\".\n",
    "- If no names are found, return: []\n",
    "\n",
    "Sentence:\n",
    "{sentence}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    output = result.stdout.decode().strip()\n",
    "\n",
    "    match = re.search(r\"\\[.*?\\]\", output, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return ast.literal_eval(match.group(0))\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "\n",
    "def extract_judges_from_dataframe(df, text_column=\"unofficial_text\", model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Extract judge names from a DataFrame containing court texts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing court text data.\n",
    "    text_column : str, optional\n",
    "        The column name in `df` that contains the court text (default is \"unofficial_text\").\n",
    "    model : str, optional\n",
    "        The language model to use for generation and parsing (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A new DataFrame with an additional 'judges' column containing lists of judge names.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"judges\"] = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        full_text = row[text_column]\n",
    "        lines = full_text.splitlines()\n",
    "        first_30 = \"\\n\".join(lines[:30])\n",
    "\n",
    "        judge_sentence = generate_judge_sentence(first_30, model=model)\n",
    "        judge_names = extract_names_from_judge_sentence(judge_sentence, model=model)\n",
    "\n",
    "        df.at[idx, \"judges\"] = judge_names\n",
    "        print(f\"Row {idx} processed.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "FC_judges = extract_judges_from_dataframe(inadmissibility_df, text_column=\"unofficial_text\")\n",
    "\n",
    "FC_judges = FC_judges.drop('Unnamed: 0', axis = 1).reset_index()\n",
    "FC_judges = FC_judges.drop('index', axis = 1)\n",
    "\n",
    "FC_judges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f77023",
   "metadata": {},
   "source": [
    "## Step 10: City (Location) Extraction\n",
    "Use llama3 from Ollama (LLM) to extract the city where each case was heard.\n",
    "\n",
    "- Extracts lines 10 through 25 from the court text, where city names are commonly mentioned in Federal Court decisions.\n",
    "\n",
    "- Prompts the language model to extract and return only the city name, or “NA” if not found.\n",
    "\n",
    "- Adds a locations column to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ecf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locations_from_text(text, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Directly extracts the city name from the given court text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The court text to analyze.\n",
    "    model : str, optional\n",
    "        The name of the language model to use (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The extracted city name, or 'NA' if no location is found.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a legal assistant. Identify the city where the case was heard from the following court text.\n",
    "\n",
    "Instructions:\n",
    "- Extract the city where the case was heard.\n",
    "- Just provide the city name, nothing else.\n",
    "- If no location is found, return NA\n",
    "\n",
    "Court Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    output = result.stdout.decode().strip()\n",
    "    \n",
    "    return output if output else \"NA\"\n",
    "\n",
    "def extract_locations_from_dataframe(df, startline, endline, text_column=\"unofficial_text\", model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Extract city names from a DataFrame containing court texts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing court text data.\n",
    "    startline : int\n",
    "        The starting line number of the text to consider.\n",
    "    endline : int\n",
    "        The ending line number of the text to consider.\n",
    "    text_column : str, optional\n",
    "        The column in `df` that contains the court text (default is \"unofficial_text\").\n",
    "    model : str, optional\n",
    "        The language model to use (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A copy of the input DataFrame with an additional 'locations' column containing extracted city names.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def extract_slice_and_location(text):\n",
    "        lines = text.splitlines()\n",
    "        selected_text = \"\\n\".join(lines[startline:endline])\n",
    "        return extract_locations_from_text(selected_text, model=model)\n",
    "\n",
    "    df[\"locations\"] = df[text_column].apply(extract_slice_and_location)\n",
    "\n",
    "    return df\n",
    "\n",
    "FC_city = extract_locations_from_dataframe(FC_judges, 10, 25,  text_column=\"unofficial_text\", model=\"llama3\")\n",
    "FC_city.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febe762",
   "metadata": {},
   "source": [
    "## Step 11: Case Outcome Extraction\n",
    "Use llama3 from Ollama (LLM) to extract legal outcome of each case.\n",
    "\n",
    "- Analyzes the last 50 to 20 lines of each case, where the court's decision is typically summarized.\n",
    "\n",
    "- Uses a language model to extract the final decision in a single word (e.g., “allowed”, “dismissed”).\n",
    "\n",
    "- Returns “unknown” if the outcome cannot be determined.\n",
    "\n",
    "- Appends the outcome as a new column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_case_outcome(text, start, end, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Extract the outcome of a legal case in a single word.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The court text from which to extract the outcome.\n",
    "    model : str, optional\n",
    "        The language model to use (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A single word summarizing the case outcome (e.g., \"allowed\", \"dismissed\", \"granted\").\n",
    "        Returns \"unknown\" if no outcome is identified.\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    relevant_text = \"\\n\".join(lines[start:end])\n",
    "    prompt = f\"\"\"\n",
    "You are a legal assistant. Your task is to determine the outcome of the court case based on the provided excerpt.\n",
    "\n",
    "Instructions:\n",
    "- Read the text carefully and identify the final decision or outcome.\n",
    "- Return only one lowercase word that best summarizes the outcome (e.g., \"allowed\", \"dismissed\", etc).\n",
    "- If the outcome is unclear or not mentioned, return \"unknown\".\n",
    "\n",
    "Court Text:\n",
    "{relevant_text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    return result.stdout.decode().strip().lower()\n",
    "\n",
    "def extract_case_outcomes_from_dataframe(df, start, end, text_column=\"unofficial_text\", model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Extract the case outcome (single word) from a DataFrame containing court texts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing court text data.\n",
    "    text_column : str, optional\n",
    "        The column name in `df` that contains the court text (default is \"unofficial_text\").\n",
    "    model : str, optional\n",
    "        The language model to use (default is \"llama3\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A new DataFrame with an additional 'outcome' column containing the extracted outcome word.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"outcome\"] = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        full_text = row[text_column]\n",
    "        try:\n",
    "            outcome = extract_case_outcome(full_text, start, end, model=model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            outcome = \"unknown\"\n",
    "\n",
    "        df.at[idx, \"outcome\"] = outcome\n",
    "        print(f\"Row {idx} processed with outcome: {outcome}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "FC_outcome = extract_case_outcomes_from_dataframe(FC_city, -50, -20)\n",
    "FC_final = FC_outcome.drop(['Unnamed: 0', 'Unnamed: 0.1', 'citation2', 'name', 'scraped_timestamp', 'unofficial_text', 'other'], axis=1)\n",
    "FC_final.to_excel(\"../data/processed/court_cases_verification.xlsx\")\n",
    "\n",
    "FC_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b96ac9",
   "metadata": {},
   "source": [
    "# Reproducibility Issues When Using Large Language Models (LLMs)\n",
    "The use of large language models, such as LLaMA 3, introduces several challenges for reproducibility in computational workflows, especially within legal reserach\n",
    "\n",
    "1. Stochastic Nature of LLMs\n",
    "- LLMs generate outputs based on probabilistic sampling.\n",
    "\n",
    "- Unless temperature and random seeds are controlled precisely (and even then, not always guaranteed), the same input prompt may yield different outputs on different runs.\n",
    "\n",
    "- This undermines deterministic reproducibility.\n",
    "\n",
    "2. Model Version Variability\n",
    "- LLMs like LLaMA 3 can be updated over time (e.g., new training data, fine-tuning changes).\n",
    "\n",
    "- A prompt run today may return a different result in future versions, making long-term reproducibility difficult without strict version pinning.\n",
    "\n",
    "3. Hardware and Deployment Differences\n",
    "- Running the same model on different systems (e.g., GPU-enabled vs CPU-only, local vs cloud-based) can affect latency, performance, and in some cases, output formatting or completeness.\n",
    "\n",
    "5. Prompt Sensitivity\n",
    "- Minor changes in wording, spacing, or line breaks in a prompt can lead to substantially different model outputs.\n",
    "\n",
    "- This sensitivity makes prompts fragile and complicates reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heron_law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
